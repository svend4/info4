# Skills ĞºĞ°Ğº Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ¸ Ğ±Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²

**Ğ”Ğ°Ñ‚Ğ°:** 2026-01-28
**ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸:** 2 Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°
**Ğ¤Ğ¾ĞºÑƒÑ:** ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

---

## ğŸ“‘ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Skills ĞºĞ°Ğº Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ](#Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚-1-skills-ĞºĞ°Ğº-Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹-ÑĞµÑ€Ğ²Ğ¸Ñ)
2. [Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Skills ĞºĞ°Ğº Ğ±Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² (Pseudo-RAG)](#Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚-2-skills-ĞºĞ°Ğº-Ğ±Ğ°Ğ·Ğ°-Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²-pseudo-rag)
3. [Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²](#ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ-Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²)
4. [Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´](#Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹-Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´)

---

# Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Skills ĞºĞ°Ğº Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ

## ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ

**Skills Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ’ĞĞ• Claude** - ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸Ñ/Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°, Ğº ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Claude Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· API.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Claude / LLM                     â”‚
â”‚         (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ AI Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ API calls
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Skills Service (Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹)               â”‚
â”‚  â€¢ Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ skills                              â”‚
â”‚  â€¢ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ skills                            â”‚
â”‚  â€¢ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ versions                          â”‚
â”‚  â€¢ Analytics                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°

âœ… **ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹**
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ»ÑĞ±Ñ‹Ğ¼ LLM (Claude, GPT, Gemini, etc.)
- ĞĞµ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·Ğ°Ğ½ Ğº ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
- ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¼ĞµĞ½ÑÑ‚ÑŒ LLM Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ skills

âœ… **Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ**
- ĞĞ´Ğ½Ğ° Ğ±Ğ°Ğ·Ğ° skills Ğ´Ğ»Ñ Ğ²ÑĞµÑ…
- Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
- Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ rollback

âœ… **ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ**
- Ğ“Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- Load balancing
- ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾Ğµ scaling Ğ¾Ñ‚ LLM

âœ… **ĞœĞ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ**
- API subscriptions
- Pay-per-use Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
- Enterprise licenses

âœ… **Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ**
- Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ security
- Rate limiting
- Access control

---

## ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Client Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Claude Codeâ”‚  â”‚   Web UI   â”‚  â”‚   Mobile   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“ HTTPS/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               API Gateway (Kong/Nginx)                â”‚
â”‚  â€¢ Authentication (JWT)                               â”‚
â”‚  â€¢ Rate limiting                                      â”‚
â”‚  â€¢ Request routing                                    â”‚
â”‚  â€¢ Response caching                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Skills Service Cluster                   â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Skills Registry â”‚    â”‚  Skills Executor â”‚        â”‚
â”‚  â”‚  â€¢ Discovery    â”‚    â”‚  â€¢ Runtime       â”‚        â”‚
â”‚  â”‚  â€¢ Metadata     â”‚    â”‚  â€¢ Sandboxing    â”‚        â”‚
â”‚  â”‚  â€¢ Versioning   â”‚    â”‚  â€¢ Monitoring    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                      â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚      Skills Storage (S3/MinIO)          â”‚        â”‚
â”‚  â”‚  â€¢ Skill definitions                     â”‚        â”‚
â”‚  â”‚  â€¢ Examples                              â”‚        â”‚
â”‚  â”‚  â€¢ Assets                                â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Cache (Redis)  â”‚    â”‚  Queue (RabbitMQ)â”‚       â”‚
â”‚  â”‚  â€¢ Hot skills    â”‚    â”‚  â€¢ Async jobs    â”‚       â”‚
â”‚  â”‚  â€¢ Results       â”‚    â”‚  â€¢ Processing    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Data Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PostgreSQL  â”‚  â”‚    MongoDB   â”‚  â”‚  ClickHouseâ”‚ â”‚
â”‚  â”‚  â€¢ Users     â”‚  â”‚  â€¢ Skills    â”‚  â”‚  â€¢ Analyticsâ”‚ â”‚
â”‚  â”‚  â€¢ Subscr.   â”‚  â”‚  â€¢ Metadata  â”‚  â”‚  â€¢ Logs    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Skills Service

```
Skills Service
â”œâ”€â”€ API Layer
â”‚   â”œâ”€â”€ REST API (FastAPI/Express)
â”‚   â”œâ”€â”€ GraphQL API
â”‚   â””â”€â”€ WebSocket (real-time)
â”‚
â”œâ”€â”€ Core Services
â”‚   â”œâ”€â”€ Skills Registry
â”‚   â”‚   â”œâ”€â”€ Registration
â”‚   â”‚   â”œâ”€â”€ Discovery
â”‚   â”‚   â”œâ”€â”€ Versioning
â”‚   â”‚   â””â”€â”€ Validation
â”‚   â”‚
â”‚   â”œâ”€â”€ Skills Executor
â”‚   â”‚   â”œâ”€â”€ Runtime Engine
â”‚   â”‚   â”œâ”€â”€ Sandboxing
â”‚   â”‚   â”œâ”€â”€ Resource Management
â”‚   â”‚   â””â”€â”€ Error Handling
â”‚   â”‚
â”‚   â”œâ”€â”€ Skills Optimizer
â”‚   â”‚   â”œâ”€â”€ Caching Strategy
â”‚   â”‚   â”œâ”€â”€ Prefetching
â”‚   â”‚   â””â”€â”€ Performance Tuning
â”‚   â”‚
â”‚   â””â”€â”€ Skills Analytics
â”‚       â”œâ”€â”€ Usage Tracking
â”‚       â”œâ”€â”€ Performance Metrics
â”‚       â””â”€â”€ Cost Attribution
â”‚
â”œâ”€â”€ Support Services
â”‚   â”œâ”€â”€ Authentication Service
â”‚   â”œâ”€â”€ Authorization Service
â”‚   â”œâ”€â”€ Billing Service
â”‚   â””â”€â”€ Notification Service
â”‚
â””â”€â”€ Storage Layer
    â”œâ”€â”€ Skills Store (S3/MinIO)
    â”œâ”€â”€ Metadata DB (MongoDB)
    â”œâ”€â”€ Relational DB (PostgreSQL)
    â”œâ”€â”€ Cache (Redis)
    â””â”€â”€ Analytics DB (ClickHouse)
```

---

## Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸

### 1. Skills Format (Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)

**Ğ’Ğ¼ĞµÑÑ‚Ğ¾ ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ² - ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ JSON/YAML:**

```yaml
# skill.yaml - ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ skill

apiVersion: skills.claude.ai/v1
kind: Skill
metadata:
  id: smart-file-organizer
  name: Smart File Organizer
  version: 2.1.0
  author: john@example.com
  license: MIT
  tags:
    - file-management
    - automation
    - productivity
  created: 2026-01-15T10:00:00Z
  updated: 2026-01-28T15:30:00Z

spec:
  description: |
    Intelligently organize files based on content, type, and metadata.
    Supports custom rules and automatic categorization.

  runtime:
    type: claude-executor  # Ğ¸Ğ»Ğ¸ python, javascript
    version: "1.0"
    timeout: 30s
    memory: 256MB

  parameters:
    input:
      type: object
      required:
        - files_path
      properties:
        files_path:
          type: string
          description: Path to files to organize
        strategy:
          type: string
          enum: [by-type, by-date, by-content, custom]
          default: by-type
        rules:
          type: array
          items:
            type: object

    output:
      type: object
      properties:
        organized_count:
          type: integer
        categories:
          type: object
        report:
          type: string

  instructions: |
    You are a file organization assistant.

    Task: Organize files from {input.files_path} using {input.strategy} strategy.

    Steps:
    1. Scan the directory
    2. Analyze each file (type, date, content)
    3. Categorize based on strategy
    4. Create folder structure
    5. Move files
    6. Generate report

    Rules:
    - Preserve original timestamps
    - Handle duplicates gracefully
    - Create backups before moving
    - Log all operations

  examples:
    - name: Organize Downloads by type
      input:
        files_path: /Users/john/Downloads
        strategy: by-type
      expected_output:
        organized_count: 45
        categories:
          Documents: 20
          Images: 15
          Videos: 10

    - name: Organize by date
      input:
        files_path: /Users/john/Documents
        strategy: by-date
        rules:
          - year_folders: true
          - month_subfolders: true

  dependencies:
    - skill: file-analyzer
      version: ">=1.0.0"
    - skill: backup-creator
      version: "^2.0.0"

  permissions:
    required:
      - filesystem:read
      - filesystem:write
    optional:
      - cloud:upload  # Ğ´Ğ»Ñ backup Ğ² cloud

  pricing:
    model: pay-per-execution
    cost: 0.01  # $0.01 per execution

  metrics:
    usage_count: 1543
    success_rate: 0.98
    avg_duration_ms: 2341
    rating: 4.7
```

### 2. API Endpoints

```python
# api.py - Skills Service API

from fastapi import FastAPI, HTTPException, Depends
from fastapi.security import HTTPBearer
from pydantic import BaseModel
from typing import Optional, Dict, Any
import asyncio

app = FastAPI(title="Skills Service API", version="1.0.0")
security = HTTPBearer()

# Models
class SkillExecuteRequest(BaseModel):
    skill_id: str
    skill_version: Optional[str] = "latest"
    input: Dict[str, Any]
    parameters: Optional[Dict[str, Any]] = {}
    async_execution: bool = False

class SkillExecuteResponse(BaseModel):
    job_id: str
    status: str  # pending, running, completed, failed
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    duration_ms: Optional[int] = None
    cost: Optional[float] = None

class SkillSearchRequest(BaseModel):
    query: Optional[str] = None
    tags: Optional[list[str]] = None
    category: Optional[str] = None
    min_rating: Optional[float] = None

# Authentication
async def verify_token(credentials = Depends(security)):
    token = credentials.credentials
    user = await auth_service.verify(token)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid token")
    return user

# Endpoints

@app.get("/")
async def root():
    return {
        "service": "Skills Service",
        "version": "1.0.0",
        "status": "operational"
    }

@app.get("/skills")
async def list_skills(
    category: Optional[str] = None,
    tag: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    user = Depends(verify_token)
):
    """Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… skills"""
    skills = await skills_registry.search(
        category=category,
        tag=tag,
        limit=limit,
        offset=offset
    )

    return {
        "skills": skills,
        "total": len(skills),
        "limit": limit,
        "offset": offset
    }

@app.get("/skills/{skill_id}")
async def get_skill(
    skill_id: str,
    version: Optional[str] = "latest",
    user = Depends(verify_token)
):
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ skill"""
    skill = await skills_registry.get(skill_id, version)

    if not skill:
        raise HTTPException(status_code=404, detail="Skill not found")

    return skill

@app.post("/skills/{skill_id}/execute")
async def execute_skill(
    skill_id: str,
    request: SkillExecuteRequest,
    user = Depends(verify_token)
):
    """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ skill"""

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°
    if not await access_control.can_execute(user, skill_id):
        raise HTTPException(status_code=403, detail="Access denied")

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ²
    if not await rate_limiter.check(user):
        raise HTTPException(status_code=429, detail="Rate limit exceeded")

    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ skill
    skill = await skills_registry.get(skill_id, request.skill_version)

    if not skill:
        raise HTTPException(status_code=404, detail="Skill not found")

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ input
    validation = skill.validate_input(request.input)
    if not validation.valid:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid input: {validation.errors}"
        )

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ job
    job = await job_manager.create_job(
        user_id=user.id,
        skill_id=skill_id,
        skill_version=skill.version,
        input=request.input,
        parameters=request.parameters
    )

    if request.async_execution:
        # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ
        asyncio.create_task(
            executor.execute(job.id, skill, request.input)
        )

        return {
            "job_id": job.id,
            "status": "pending",
            "message": "Job queued for execution"
        }
    else:
        # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ
        result = await executor.execute(job.id, skill, request.input)

        # Billing
        await billing_service.record_usage(
            user_id=user.id,
            skill_id=skill_id,
            cost=skill.pricing.cost
        )

        return {
            "job_id": job.id,
            "status": "completed",
            "result": result.output,
            "duration_ms": result.duration_ms,
            "cost": skill.pricing.cost
        }

@app.get("/jobs/{job_id}")
async def get_job_status(
    job_id: str,
    user = Depends(verify_token)
):
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ job"""
    job = await job_manager.get(job_id)

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    if job.user_id != user.id:
        raise HTTPException(status_code=403, detail="Access denied")

    return {
        "job_id": job.id,
        "status": job.status,
        "result": job.result if job.status == "completed" else None,
        "error": job.error if job.status == "failed" else None,
        "progress": job.progress,
        "duration_ms": job.duration_ms
    }

@app.post("/skills/search")
async def search_skills(
    request: SkillSearchRequest,
    user = Depends(verify_token)
):
    """ĞŸĞ¾Ğ¸ÑĞº skills"""
    results = await skills_registry.search(
        query=request.query,
        tags=request.tags,
        category=request.category,
        min_rating=request.min_rating
    )

    return {
        "results": results,
        "count": len(results)
    }

@app.post("/skills")
async def register_skill(
    skill_data: dict,
    user = Depends(verify_token)
):
    """Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ skill"""

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
    skill = Skill.parse(skill_data)

    if not skill.valid:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid skill: {skill.errors}"
        )

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ°Ğ²
    if not user.can_create_skills:
        raise HTTPException(status_code=403, detail="Access denied")

    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ
    registered = await skills_registry.register(
        skill=skill,
        author_id=user.id
    )

    return {
        "skill_id": registered.id,
        "version": registered.version,
        "status": "registered",
        "message": "Skill registered successfully"
    }

@app.delete("/skills/{skill_id}")
async def delete_skill(
    skill_id: str,
    user = Depends(verify_token)
):
    """Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ skill"""
    skill = await skills_registry.get(skill_id)

    if not skill:
        raise HTTPException(status_code=404, detail="Skill not found")

    if skill.author_id != user.id and not user.is_admin:
        raise HTTPException(status_code=403, detail="Access denied")

    await skills_registry.delete(skill_id)

    return {"message": "Skill deleted successfully"}

# WebSocket Ğ´Ğ»Ñ real-time execution
from fastapi import WebSocket

@app.websocket("/ws/execute")
async def websocket_execute(websocket: WebSocket):
    """WebSocket endpoint Ğ´Ğ»Ñ streaming execution"""
    await websocket.accept()

    try:
        # ĞÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
        auth_data = await websocket.receive_json()
        user = await auth_service.verify(auth_data['token'])

        if not user:
            await websocket.send_json({"error": "Authentication failed"})
            await websocket.close()
            return

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        request = await websocket.receive_json()

        skill_id = request['skill_id']
        input_data = request['input']

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ skill
        skill = await skills_registry.get(skill_id)

        # Execute Ñ streaming
        async for chunk in executor.execute_stream(skill, input_data):
            await websocket.send_json({
                "type": "chunk",
                "data": chunk
            })

        await websocket.send_json({
            "type": "complete",
            "message": "Execution completed"
        })

    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "error": str(e)
        })
    finally:
        await websocket.close()
```

### 3. Skills Executor

```python
# executor.py - Skills execution engine

import asyncio
import docker
import resource
from typing import Any, Dict
import time

class SkillsExecutor:
    """Ğ”Ğ²Ğ¸Ğ¶Ğ¾Ğº Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ skills"""

    def __init__(self):
        self.docker_client = docker.from_env()
        self.claude_client = Claude(api_key=settings.CLAUDE_API_KEY)

    async def execute(
        self,
        job_id: str,
        skill: Skill,
        input_data: Dict[str, Any]
    ) -> ExecutionResult:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ skill"""

        start_time = time.time()

        try:
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ
            await job_manager.update_status(job_id, "running")

            # Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ runtime
            if skill.runtime.type == "claude-executor":
                result = await self.execute_claude(skill, input_data)
            elif skill.runtime.type == "python":
                result = await self.execute_python(skill, input_data)
            elif skill.runtime.type == "javascript":
                result = await self.execute_javascript(skill, input_data)
            else:
                raise ValueError(f"Unsupported runtime: {skill.runtime.type}")

            duration_ms = int((time.time() - start_time) * 1000)

            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            exec_result = ExecutionResult(
                job_id=job_id,
                status="completed",
                output=result,
                duration_ms=duration_ms
            )

            await job_manager.update(job_id, exec_result)

            return exec_result

        except Exception as e:
            duration_ms = int((time.time() - start_time) * 1000)

            exec_result = ExecutionResult(
                job_id=job_id,
                status="failed",
                error=str(e),
                duration_ms=duration_ms
            )

            await job_manager.update(job_id, exec_result)

            raise

    async def execute_claude(
        self,
        skill: Skill,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ skill Ñ‡ĞµÑ€ĞµĞ· Claude API"""

        # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        prompt = self.build_prompt(skill, input_data)

        # Ğ’Ñ‹Ğ·Ğ²Ğ°Ñ‚ÑŒ Claude
        response = await self.claude_client.messages.create(
            model=skill.runtime.model or "claude-sonnet-4",
            max_tokens=skill.runtime.max_tokens or 4096,
            temperature=skill.runtime.temperature or 1.0,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        # ĞŸĞ°Ñ€ÑĞ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
        result = self.parse_claude_response(response, skill)

        return result

    def build_prompt(
        self,
        skill: Skill,
        input_data: Dict[str, Any]
    ) -> str:
        """ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Claude"""

        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸
        prompt = skill.instructions

        # ĞŸĞ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ input Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        for key, value in input_data.items():
            prompt = prompt.replace(f"{{input.{key}}}", str(value))

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹
        if skill.examples:
            prompt += "\n\nExamples:\n"
            for example in skill.examples[:3]:  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 3 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°
                prompt += f"\nInput: {example.input}"
                prompt += f"\nExpected Output: {example.expected_output}\n"

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ output format
        if skill.parameters.output:
            prompt += f"\n\nOutput format: {skill.parameters.output}"

        return prompt

    def parse_claude_response(
        self,
        response: Any,
        skill: Skill
    ) -> Dict[str, Any]:
        """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Claude"""

        content = response.content[0].text

        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚Ğ°Ñ‚ÑŒÑÑ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ JSON ĞµÑĞ»Ğ¸ output - Ğ¾Ğ±ÑŠĞµĞºÑ‚
        if skill.parameters.output.get('type') == 'object':
            try:
                import json
                # ĞĞ°Ğ¹Ñ‚Ğ¸ JSON Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ
                start = content.find('{')
                end = content.rfind('}') + 1
                if start >= 0 and end > start:
                    json_str = content[start:end]
                    return json.loads(json_str)
            except:
                pass

        # Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞºĞ°Ğº Ñ‚ĞµĞºÑÑ‚
        return {"output": content}

    async def execute_python(
        self,
        skill: Skill,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Python skill Ğ² sandboxed environment"""

        # Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ² Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğµ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸
        container = self.docker_client.containers.run(
            image="python:3.11-slim",
            command=[
                "python", "-c",
                skill.code  # Python ĞºĞ¾Ğ´ skill
            ],
            environment={
                "SKILL_INPUT": json.dumps(input_data)
            },
            mem_limit=skill.runtime.memory,
            cpu_quota=int(skill.runtime.cpu * 100000),  # CPU limit
            network_mode="none",  # Ğ‘ĞµĞ· network Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°
            remove=True,
            detach=False,
            stdout=True,
            stderr=True
        )

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ output
        output = container.decode('utf-8')

        return json.loads(output)

    async def execute_javascript(
        self,
        skill: Skill,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ JavaScript skill"""

        # ĞĞ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾ Python, Ğ½Ğ¾ Ñ Node.js ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ¼
        container = self.docker_client.containers.run(
            image="node:18-slim",
            command=[
                "node", "-e",
                skill.code
            ],
            environment={
                "SKILL_INPUT": json.dumps(input_data)
            },
            mem_limit=skill.runtime.memory,
            remove=True,
            detach=False,
            stdout=True
        )

        output = container.decode('utf-8')

        return json.loads(output)

    async def execute_stream(
        self,
        skill: Skill,
        input_data: Dict[str, Any]
    ):
        """Streaming execution Ğ´Ğ»Ñ long-running skills"""

        prompt = self.build_prompt(skill, input_data)

        # Stream Ğ¾Ñ‚ Claude
        async with self.claude_client.messages.stream(
            model="claude-sonnet-4",
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            async for chunk in stream:
                if chunk.type == "content_block_delta":
                    yield chunk.delta.text

# Resource limits
class ResourceManager:
    """Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸ Ğ´Ğ»Ñ execution"""

    @staticmethod
    def set_limits(memory_mb: int, cpu_percent: float):
        """Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²"""

        # Memory limit
        memory_bytes = memory_mb * 1024 * 1024
        resource.setrlimit(
            resource.RLIMIT_AS,
            (memory_bytes, memory_bytes)
        )

        # CPU limit (Ñ‡ĞµÑ€ĞµĞ· cgroups Ğ² Docker)
        pass

    @staticmethod
    def monitor_usage():
        """ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²"""
        import psutil

        return {
            "cpu_percent": psutil.cpu_percent(),
            "memory_mb": psutil.virtual_memory().used / 1024 / 1024,
            "disk_io": psutil.disk_io_counters()
        }
```

### 4. ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Claude Code

```python
# claude_code_integration.py - Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Claude Code

from typing import Optional
import httpx

class SkillsServiceClient:
    """Client Ğ´Ğ»Ñ Skills Service Ğ¸Ğ· Claude Code"""

    def __init__(
        self,
        api_url: str,
        api_key: str
    ):
        self.api_url = api_url
        self.api_key = api_key
        self.client = httpx.AsyncClient(
            base_url=api_url,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            timeout=30.0
        )

    async def list_skills(
        self,
        category: Optional[str] = None,
        tag: Optional[str] = None
    ):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº skills"""
        params = {}
        if category:
            params['category'] = category
        if tag:
            params['tag'] = tag

        response = await self.client.get("/skills", params=params)
        response.raise_for_status()

        return response.json()

    async def execute_skill(
        self,
        skill_id: str,
        input_data: dict,
        async_execution: bool = False
    ):
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ skill"""
        payload = {
            "skill_id": skill_id,
            "input": input_data,
            "async_execution": async_execution
        }

        response = await self.client.post(
            f"/skills/{skill_id}/execute",
            json=payload
        )
        response.raise_for_status()

        return response.json()

    async def get_job_status(self, job_id: str):
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ job"""
        response = await self.client.get(f"/jobs/{job_id}")
        response.raise_for_status()

        return response.json()

    async def search_skills(self, query: str):
        """ĞŸĞ¾Ğ¸ÑĞº skills"""
        response = await self.client.post(
            "/skills/search",
            json={"query": query}
        )
        response.raise_for_status()

        return response.json()


# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Claude Code
class SkillsTool:
    """Tool Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Skills Service Ğ² Claude Code"""

    def __init__(self, config):
        self.client = SkillsServiceClient(
            api_url=config.get('skills_service_url', 'https://api.skills.com'),
            api_key=config.get('skills_api_key')
        )

    async def use_skill(
        self,
        skill_name: str,
        input_data: dict
    ) -> dict:
        """Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ skill Ğ¸Ğ· Claude Code"""

        # ĞŸĞ¾Ğ¸ÑĞº skill Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸
        search_result = await self.client.search_skills(skill_name)

        if not search_result['results']:
            raise ValueError(f"Skill '{skill_name}' not found")

        skill = search_result['results'][0]

        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ
        result = await self.client.execute_skill(
            skill_id=skill['id'],
            input_data=input_data
        )

        return result

    async def list_available_skills(self, category: str = None):
        """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ skills"""
        skills = await self.client.list_skills(category=category)

        return skills['skills']

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ² Claude Code MCP
class SkillsServiceMCP:
    """MCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ Skills Service"""

    def __init__(self):
        self.tools = [
            {
                "name": "use_skill",
                "description": "Execute a skill from Skills Service",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "skill_name": {
                            "type": "string",
                            "description": "Name of the skill to execute"
                        },
                        "input_data": {
                            "type": "object",
                            "description": "Input data for the skill"
                        }
                    },
                    "required": ["skill_name", "input_data"]
                }
            },
            {
                "name": "list_skills",
                "description": "List available skills",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "category": {
                            "type": "string",
                            "description": "Filter by category"
                        }
                    }
                }
            },
            {
                "name": "search_skills",
                "description": "Search for skills",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "Search query"
                        }
                    },
                    "required": ["query"]
                }
            }
        ]

    async def call_tool(self, tool_name: str, arguments: dict):
        """Handle tool calls"""
        client = SkillsTool(config)

        if tool_name == "use_skill":
            return await client.use_skill(
                arguments['skill_name'],
                arguments['input_data']
            )
        elif tool_name == "list_skills":
            return await client.list_available_skills(
                arguments.get('category')
            )
        elif tool_name == "search_skills":
            return await client.client.search_skills(
                arguments['query']
            )
```

---

## Deployment

### Docker Compose

```yaml
# docker-compose.yml

version: '3.8'

services:
  # API Gateway
  kong:
    image: kong:3.4
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_DATABASE: kong
    ports:
      - "8000:8000"  # HTTP
      - "8443:8443"  # HTTPS
      - "8001:8001"  # Admin API
    depends_on:
      - postgres

  # Skills Service
  skills-api:
    build: ./skills-service
    environment:
      DATABASE_URL: postgresql://user:pass@postgres:5432/skills
      REDIS_URL: redis://redis:6379
      MONGO_URL: mongodb://mongo:27017
      S3_ENDPOINT: http://minio:9000
      CLAUDE_API_KEY: ${CLAUDE_API_KEY}
    deploy:
      replicas: 3
    depends_on:
      - postgres
      - redis
      - mongo
      - minio

  # PostgreSQL
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: skills
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redis
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

  # MongoDB
  mongo:
    image: mongo:7
    volumes:
      - mongo_data:/data/db

  # MinIO (S3-compatible)
  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"
      - "15672:15672"

  # ClickHouse (Analytics)
  clickhouse:
    image: clickhouse/clickhouse-server
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse

volumes:
  postgres_data:
  redis_data:
  mongo_data:
  minio_data:
  clickhouse_data:
```

### Kubernetes

```yaml
# k8s-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: skills-service
spec:
  replicas: 5
  selector:
    matchLabels:
      app: skills-service
  template:
    metadata:
      labels:
        app: skills-service
    spec:
      containers:
      - name: api
        image: skills-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: skills-secrets
              key: database-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: skills-service
spec:
  selector:
    app: skills-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: skills-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: skills-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°

âœ… **Platform-agnostic**
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ»ÑĞ±Ñ‹Ğ¼ LLM
- Claude Code, ChatGPT, Gemini Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ

âœ… **Scalability**
- Horizontal scaling
- Load balancing
- Auto-scaling Ğ¿Ğ¾ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ

âœ… **Security**
- Sandboxed execution
- Resource limits
- Access control
- Rate limiting

âœ… **Monitoring**
- Detailed analytics
- Performance metrics
- Cost attribution
- Error tracking

âœ… **Flexibility**
- ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ skills (YAML)
- Multiple runtimes (Claude, Python, JS)
- Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- A/B testing

âœ… **Monetization**
- Pay-per-use
- Subscriptions
- Enterprise licenses
- API marketplace

---

(ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ñ Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ¼ 2: Skills ĞºĞ°Ğº Ğ±Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²...)

FUTURE_EOF

echo "âœ… Ğ§Ğ°ÑÑ‚ÑŒ 1 ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1 (Skills ĞºĞ°Ğº Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ)"

# Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Skills ĞºĞ°Ğº Ğ±Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² (Pseudo-RAG)

## ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ

**Skills = Ğ‘Ğ°Ğ·Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²**, Ğº ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ AI Ğ¾Ğ±Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ÑÑ ĞŸĞ•Ğ Ğ•Ğ” Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹/Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ                  â”‚
â”‚  "Organize 1000 files by type and date"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“ 1. Query Method DB
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Skills Method Database                 â”‚
â”‚  â€¢ Semantic search Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸                   â”‚
â”‚  â€¢ ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹                   â”‚
â”‚  â€¢ Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ½Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹, Ğ° ĞœĞ•Ğ¢ĞĞ”Ğ«               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“ 2. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    [file-organizer, batch-processor,            â”‚
â”‚     backup-creator, progress-tracker]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“ 3. AI ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AI Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ:            â”‚
â”‚  1. backup-creator (ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ backup)             â”‚
â”‚  2. file-organizer (organize)                   â”‚
â”‚  3. batch-processor (Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¸Ñ‚ÑŒ Ğ¿Ğ¾ batch)       â”‚
â”‚  4. progress-tracker (Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ RAG

**ĞšĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ RAG:**
```python
# RAG Ğ¸Ñ‰ĞµÑ‚ ĞĞ¢Ğ’Ğ•Ğ¢Ğ«/ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢
query = "What is machine learning?"
documents = vector_db.search(query)
# â†’ Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸ ML
context = documents[0].content  # "Machine learning is..."
answer = llm.generate(query, context=context)
```

**Skills Method DB (Pseudo-RAG):**
```python
# Method DB Ğ¸Ñ‰ĞµÑ‚ ĞœĞ•Ğ¢ĞĞ”Ğ«/Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ«
task = "Train a machine learning model"
methods = method_db.search(task)
# â†’ Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ ĞœĞ•Ğ¢ĞĞ”Ğ«
# methods = [
#   'data-preprocessor',
#   'model-trainer',
#   'hyperparameter-tuner',
#   'model-evaluator'
# ]

# AI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ°Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
solution = llm.solve_with_methods(task, available_methods=methods)
```

**ĞĞ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ:**
- RAG = Ğ‘Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ñ ĞºĞ½Ğ¸Ğ³Ğ°Ğ¼Ğ¸ (Ğ¸Ñ‰ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ)
- Method DB = Ğ¯Ñ‰Ğ¸Ğº Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ (Ğ¸Ñ‰ĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹)

---

## ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Method Database

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI Agent/LLM                         â”‚
â”‚  â€¢ ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ                                   â”‚
â”‚  â€¢ Ğ—Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹                    â”‚
â”‚  â€¢ ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ                               â”‚
â”‚  â€¢ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“ Query Interface
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Method Query Engine                      â”‚
â”‚  â€¢ Semantic matching (Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â†” Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹)              â”‚
â”‚  â€¢ Relevance scoring                                 â”‚
â”‚  â€¢ Method ranking                                    â”‚
â”‚  â€¢ Composition suggestions                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Vector Database (Embeddings)                â”‚
â”‚  â€¢ Method embeddings                                 â”‚
â”‚  â€¢ Task embeddings                                   â”‚
â”‚  â€¢ Capability embeddings                             â”‚
â”‚  â€¢ Similar methods clustering                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Skills Method Repository                 â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Method Metadata Store (MongoDB)               â”‚ â”‚
â”‚  â”‚  â€¢ Method descriptions                         â”‚ â”‚
â”‚  â”‚  â€¢ Capabilities                                â”‚ â”‚
â”‚  â”‚  â€¢ Prerequisites                               â”‚ â”‚
â”‚  â”‚  â€¢ Use cases                                   â”‚ â”‚
â”‚  â”‚  â€¢ Success criteria                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Method Implementations (S3)                   â”‚ â”‚
â”‚  â”‚  â€¢ Code/instructions                           â”‚ â”‚
â”‚  â”‚  â€¢ Examples                                    â”‚ â”‚
â”‚  â”‚  â€¢ Test cases                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Method Relations (Graph DB)                   â”‚ â”‚
â”‚  â”‚  â€¢ Dependencies                                â”‚ â”‚
â”‚  â”‚  â€¢ Compositions                                â”‚ â”‚
â”‚  â”‚  â€¢ Alternatives                                â”‚ â”‚
â”‚  â”‚  â€¢ Complementary methods                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸

### 1. Method Schema

```yaml
# method.yaml - Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ² Ğ±Ğ°Ğ·Ğµ

apiVersion: methods.ai/v1
kind: Method
metadata:
  id: file-organizer-by-type
  name: File Organizer by Type
  version: 1.0.0
  category: file-management
  tags:
    - files
    - organization
    - automation

# Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ (Ğ´Ğ»Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°)
semantics:
  purpose: |
    Organize files into folders based on their types (extensions).
    Analyzes file extensions and creates appropriate folder structure.

  capabilities:
    - Detect file types by extension
    - Create categorized folder structure
    - Move files to appropriate folders
    - Handle duplicates
    - Generate organization report

  suitable_for:
    - Large number of unsorted files
    - Mixed file types in one location
    - Need for automatic categorization
    - Bulk file organization

  not_suitable_for:
    - Files requiring content analysis
    - Complex business logic sorting
    - Custom naming schemes

  prerequisites:
    - Read/write filesystem access
    - Files to organize are in single directory

  outcomes:
    - Files organized into type-based folders
    - Original files optionally backed up
    - Organization report generated

# Embedding Ğ´Ğ»Ñ semantic search
embedding:
  model: text-embedding-3-large
  vector: [0.123, -0.456, 0.789, ...]  # 3072-dim vector
  last_updated: 2026-01-28T10:00:00Z

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ´Ğ»Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚
use_cases:
  - description: Organize cluttered Downloads folder
    input_example: "I have 500 files in Downloads, need to organize them"
    relevance_score: 0.95

  - description: Sort project files by type
    input_example: "Separate images, docs, and code files"
    relevance_score: 0.90

  - description: Clean up desktop files
    input_example: "Desktop has too many files, organize by extension"
    relevance_score: 0.88

# Ğ¡Ğ²ÑĞ·Ğ¸ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸
relations:
  complements:
    - method_id: backup-creator
      reason: Good to backup before organizing
      score: 0.85

    - method_id: duplicate-finder
      reason: Find duplicates before organizing
      score: 0.80

  alternatives:
    - method_id: file-organizer-by-date
      reason: Alternative organizing strategy
      when_to_prefer: When chronological order more important

    - method_id: file-organizer-by-content
      reason: More advanced, content-based
      when_to_prefer: When need semantic organization

  depends_on:
    - method_id: file-type-detector
      required: true

  enables:
    - method_id: file-search-optimizer
      reason: Organized files easier to search

# ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
metrics:
  usage_count: 1543
  success_rate: 0.94
  avg_duration_seconds: 12.5
  user_rating: 4.6
  common_failures:
    - Permission denied: 15%
    - Insufficient disk space: 8%
    - Invalid file names: 3%

# Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ AI
ai_instructions:
  when_to_use: |
    Use this method when user wants to organize files by type/extension.
    Suitable for bulk file organization tasks.
    Not suitable if content-based organization needed.

  how_to_use: |
    1. Verify user has target directory path
    2. Ask if backup needed (recommend yes)
    3. Call method with directory path
    4. Show organization report to user

  parameters:
    source_directory:
      type: path
      required: true
      description: Directory containing files to organize

    create_backup:
      type: boolean
      default: true
      description: Create backup before organizing

    folder_mapping:
      type: object
      optional: true
      description: Custom extension -> folder mappings

  expected_output:
    organized_count: integer
    folder_structure: object
    errors: array

# Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
implementation:
  type: claude-skill
  instructions_url: s3://methods/file-organizer-by-type/instructions.md
  examples_url: s3://methods/file-organizer-by-type/examples.json
  code_url: s3://methods/file-organizer-by-type/code.py  # optional
```

### 2. Method Query Engine

```python
# method_query_engine.py

from typing import List, Dict, Any
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss

class MethodQueryEngine:
    """Ğ”Ğ²Ğ¸Ğ¶Ğ¾Ğº Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²"""

    def __init__(self):
        # ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ embeddings
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')

        # Vector database (FAISS)
        self.index = faiss.IndexFlatL2(384)  # 384-dim embeddings

        # Metadata store
        self.methods_db = MethodsDatabase()

        # Graph Ğ´Ğ»Ñ relations
        self.graph = MethodRelationGraph()

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        self.load_methods()

    def load_methods(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² vector DB"""
        methods = self.methods_db.get_all_methods()

        for method in methods:
            # Ğ•ÑĞ»Ğ¸ embedding ÑƒĞ¶Ğµ ĞµÑÑ‚ÑŒ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ
            if method.get('embedding'):
                vector = np.array(method['embedding']['vector'])
            else:
                # Ğ˜Ğ½Ğ°Ñ‡Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ
                vector = self.create_embedding(method)

            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² FAISS index
            self.index.add(vector.reshape(1, -1))

    def create_embedding(self, method: Dict) -> np.ndarray:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ embedding Ğ´Ğ»Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°"""
        # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ¾Ğ»Ñ
        text = f"""
        {method['semantics']['purpose']}

        Capabilities: {', '.join(method['semantics']['capabilities'])}

        Suitable for: {', '.join(method['semantics']['suitable_for'])}

        Use cases: {' '.join([uc['description'] for uc in method['use_cases']])}
        """

        embedding = self.encoder.encode(text)

        return embedding

    def search_methods(
        self,
        task_description: str,
        top_k: int = 5,
        min_relevance: float = 0.7
    ) -> List[Dict]:
        """
        ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸

        Args:
            task_description: ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            top_k: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
            min_relevance: ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ

        Returns:
            List Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ scores
        """

        # 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ embedding Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        task_embedding = self.encoder.encode(task_description)

        # 2. ĞŸĞ¾Ğ¸ÑĞº Ğ² FAISS
        distances, indices = self.index.search(
            task_embedding.reshape(1, -1),
            top_k * 2  # Ğ˜Ñ‰ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
        )

        # 3. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        candidates = []
        for distance, idx in zip(distances[0], indices[0]):
            # Convert distance to similarity score
            similarity = 1 / (1 + distance)

            if similarity >= min_relevance:
                method = self.methods_db.get_method_by_index(idx)
                candidates.append({
                    'method': method,
                    'similarity_score': similarity,
                    'distance': distance
                })

        # 4. Re-ranking Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
        ranked = self.rerank_methods(
            candidates,
            task_description
        )

        # 5. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        enhanced = self.add_complementary_methods(ranked)

        return enhanced[:top_k]

    def rerank_methods(
        self,
        candidates: List[Dict],
        task: str
    ) -> List[Dict]:
        """Re-ranking Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²"""

        for candidate in candidates:
            method = candidate['method']

            # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ score - semantic similarity
            base_score = candidate['similarity_score']

            # ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° (success rate, rating)
            quality_score = (
                method['metrics']['success_rate'] * 0.6 +
                (method['metrics']['user_rating'] / 5.0) * 0.4
            )

            # ĞŸĞ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ½Ğ¾ Ğ½Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ²ĞµÑ)
            popularity_score = min(
                method['metrics']['usage_count'] / 1000.0,
                1.0
            )

            # ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ score
            final_score = (
                base_score * 0.60 +
                quality_score * 0.25 +
                popularity_score * 0.15
            )

            candidate['final_score'] = final_score

        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ final_score
        ranked = sorted(
            candidates,
            key=lambda x: x['final_score'],
            reverse=True
        )

        return ranked

    def add_complementary_methods(
        self,
        methods: List[Dict]
    ) -> List[Dict]:
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹"""

        enhanced = []

        for method_data in methods:
            method = method_data['method']
            enhanced.append(method_data)

            # ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ½Ñ‹Ğµ
            complements = method.get('relations', {}).get('complements', [])

            for complement in complements[:2]:  # Ğ¢Ğ¾Ğ¿-2 ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ½Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ Ğ»Ğ¸ ÑƒĞ¶Ğµ
                if not any(e['method']['id'] == complement['method_id'] for e in enhanced):
                    complement_method = self.methods_db.get_method(
                        complement['method_id']
                    )

                    enhanced.append({
                        'method': complement_method,
                        'final_score': complement['score'],
                        'relationship': 'complement',
                        'reason': complement['reason']
                    })

        return enhanced

    def suggest_method_composition(
        self,
        task: str,
        methods: List[Dict]
    ) -> Dict:
        """ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"""

        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ LLM Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        prompt = f"""
        Task: {task}

        Available methods:
        {self._format_methods_for_prompt(methods)}

        Suggest a composition (sequence/pipeline) of these methods to solve the task.

        Consider:
        - Method dependencies
        - Logical order
        - Complementary methods
        - Prerequisites and outcomes

        Return JSON:
        {{
            "pipeline": [
                {{
                    "step": 1,
                    "method_id": "...",
                    "reason": "why this method at this step"
                }},
                ...
            ],
            "rationale": "overall explanation"
        }}
        """

        # Call LLM
        composition = llm.generate(prompt)

        return composition

    def _format_methods_for_prompt(self, methods: List[Dict]) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°"""
        formatted = []

        for m in methods:
            method = m['method']
            formatted.append(f"""
            - {method['name']} (ID: {method['id']})
              Purpose: {method['semantics']['purpose'][:200]}
              Capabilities: {', '.join(method['semantics']['capabilities'][:3])}
              Score: {m.get('final_score', 0):.2f}
            """)

        return '\n'.join(formatted)


class MethodComposer:
    """ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ² pipeline"""

    def __init__(self):
        self.methods_db = MethodsDatabase()

    def create_pipeline(
        self,
        method_ids: List[str]
    ) -> 'MethodPipeline':
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ pipeline Ğ¸Ğ· Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²"""

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        methods = [
            self.methods_db.get_method(mid)
            for mid in method_ids
        ]

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ dependencies
        self.validate_dependencies(methods)

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ pipeline
        pipeline = MethodPipeline(methods)

        return pipeline

    def validate_dependencies(self, methods: List[Dict]):
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸"""

        for i, method in enumerate(methods):
            depends_on = method.get('relations', {}).get('depends_on', [])

            for dep in depends_on:
                if dep['required']:
                    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾ dependency ĞµÑÑ‚ÑŒ Ğ´Ğ¾ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°
                    dep_found = any(
                        m['id'] == dep['method_id']
                        for m in methods[:i]
                    )

                    if not dep_found:
                        raise ValueError(
                            f"Method {method['name']} requires {dep['method_id']} "
                            f"but it's not in pipeline before this method"
                        )

    def suggest_order(
        self,
        methods: List[Dict]
    ) -> List[Dict]:
        """ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²"""

        # Topological sort Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ dependencies
        from collections import defaultdict, deque

        # Build dependency graph
        graph = defaultdict(list)
        in_degree = defaultdict(int)

        for method in methods:
            method_id = method['id']
            in_degree[method_id] = 0

        for method in methods:
            method_id = method['id']
            deps = method.get('relations', {}).get('depends_on', [])

            for dep in deps:
                graph[dep['method_id']].append(method_id)
                in_degree[method_id] += 1

        # Topological sort
        queue = deque([
            mid for mid in in_degree
            if in_degree[mid] == 0
        ])

        ordered = []

        while queue:
            method_id = queue.popleft()
            ordered.append(method_id)

            for neighbor in graph[method_id]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)

        # Convert back to methods
        ordered_methods = [
            next(m for m in methods if m['id'] == mid)
            for mid in ordered
        ]

        return ordered_methods


class MethodPipeline:
    """Pipeline Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ"""

    def __init__(self, methods: List[Dict]):
        self.methods = methods
        self.current_step = 0
        self.results = []

    async def execute(self, initial_input: Any):
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ²ĞµÑÑŒ pipeline"""

        current_data = initial_input

        for i, method in enumerate(self.methods):
            self.current_step = i

            print(f"Executing step {i+1}/{len(self.methods)}: {method['name']}")

            # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´
            result = await self.execute_method(method, current_data)

            self.results.append({
                'step': i + 1,
                'method': method['name'],
                'result': result
            })

            # Output ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° = input ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾
            current_data = result

        return {
            'final_result': current_data,
            'steps': self.results
        }

    async def execute_method(self, method: Dict, input_data: Any):
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ Ğ¼ĞµÑ‚Ğ¾Ğ´"""

        # Load implementation
        implementation = await self.load_implementation(method)

        # Execute
        if method['implementation']['type'] == 'claude-skill':
            result = await self.execute_claude_skill(
                implementation,
                input_data
            )
        elif method['implementation']['type'] == 'python':
            result = await self.execute_python(
                implementation,
                input_data
            )
        # etc.

        return result
```

### 3. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ AI

```python
# ai_integration.py - ĞšĞ°Ğº AI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Method DB

from typing import List, Dict, Any

class AIMethodAgent:
    """AI Ğ°Ğ³ĞµĞ½Ñ‚, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Method DB"""

    def __init__(self):
        self.query_engine = MethodQueryEngine()
        self.composer = MethodComposer()
        self.executor = MethodExecutor()

    async def solve_task(self, task_description: str) -> Any:
        """
        Ğ ĞµÑˆĞ¸Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹

        Workflow:
        1. ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
        2. ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        3. Ğ¡ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½Ğ¾Ğ²Ğ°Ñ‚ÑŒ pipeline
        4. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ
        5. Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
        """

        print(f"ğŸ“‹ Task: {task_description}")

        # 1. Analyze task
        task_analysis = await self.analyze_task(task_description)

        print(f"ğŸ” Task type: {task_analysis['type']}")
        print(f"ğŸ¯ Key requirements: {task_analysis['requirements']}")

        # 2. Search methods
        methods = self.query_engine.search_methods(
            task_description,
            top_k=10
        )

        print(f"ğŸ”§ Found {len(methods)} relevant methods")
        for m in methods[:3]:
            print(f"  - {m['method']['name']} (score: {m['final_score']:.2f})")

        # 3. Suggest composition
        composition = self.query_engine.suggest_method_composition(
            task_description,
            methods
        )

        print(f"ğŸ“ Suggested pipeline:")
        for step in composition['pipeline']:
            method_name = next(
                m['method']['name']
                for m in methods
                if m['method']['id'] == step['method_id']
            )
            print(f"  {step['step']}. {method_name}")
            print(f"     Reason: {step['reason']}")

        # 4. Ask user for confirmation (optional)
        # confirmed = input("Proceed with this plan? (y/n): ")

        # 5. Execute pipeline
        pipeline = self.composer.create_pipeline([
            step['method_id']
            for step in composition['pipeline']
        ])

        result = await pipeline.execute(
            initial_input=task_analysis['input_data']
        )

        print(f"âœ… Task completed!")

        return result

    async def analyze_task(self, task: str) -> Dict:
        """ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ"""

        # Use LLM to understand task
        analysis_prompt = f"""
        Analyze this task:
        "{task}"

        Extract:
        1. Task type (e.g., file_management, data_processing, content_creation)
        2. Key requirements
        3. Input data (what user is starting with)
        4. Expected output
        5. Constraints or preferences

        Return JSON.
        """

        analysis = await llm.generate(analysis_prompt)

        return analysis

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

agent = AIMethodAgent()

# ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ´Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
task = """
I have a folder with 1000 mixed files (images, documents, videos).
I need to:
1. Organize them by type
2. Find and remove duplicates
3. Compress images to save space
4. Create a backup
5. Generate a report
"""

# AI Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹
result = await agent.solve_task(task)

# Output:
# ğŸ“‹ Task: I have a folder with 1000 mixed files...
# ğŸ” Task type: file_management
# ğŸ¯ Key requirements: ['organize', 'deduplicate', 'compress', 'backup', 'report']
# ğŸ”§ Found 10 relevant methods
#   - File Organizer by Type (score: 0.94)
#   - Duplicate Finder (score: 0.89)
#   - Image Compressor (score: 0.87)
# ğŸ“ Suggested pipeline:
#   1. Backup Creator
#      Reason: Create backup before any modifications
#   2. Duplicate Finder
#      Reason: Find duplicates before organizing to avoid moving duplicates
#   3. File Organizer by Type
#      Reason: Main organization task
#   4. Image Compressor
#      Reason: Compress images in organized folders
#   5. Report Generator
#      Reason: Generate final report
# âœ… Task completed!
```

### 4. Ğ˜Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²

```python
# method_indexer.py - Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²

class MethodIndexer:
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ² Ğ±Ğ°Ğ·Ñƒ"""

    def __init__(self):
        self.query_engine = MethodQueryEngine()
        self.methods_db = MethodsDatabase()

    async def index_method(self, method: Dict):
        """
        Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´

        1. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
        2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ embedding
        3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² DB
        4. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ² vector index
        5. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ relations
        """

        # 1. Validate
        validation = self.validate_method(method)
        if not validation.valid:
            raise ValueError(f"Invalid method: {validation.errors}")

        # 2. Create embedding
        embedding = self.query_engine.create_embedding(method)
        method['embedding'] = {
            'model': 'all-MiniLM-L6-v2',
            'vector': embedding.tolist(),
            'created_at': datetime.now()
        }

        # 3. Save to database
        method_id = await self.methods_db.save_method(method)

        # 4. Add to vector index
        self.query_engine.index.add(embedding.reshape(1, -1))

        # 5. Update relations graph
        await self.update_relations(method)

        print(f"âœ… Method '{method['name']}' indexed successfully")
        print(f"   ID: {method_id}")

        return method_id

    async def bulk_index(self, methods: List[Dict]):
        """ĞœĞ°ÑÑĞ¾Ğ²Ğ¾Ğµ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ"""

        for method in methods:
            try:
                await self.index_method(method)
            except Exception as e:
                print(f"âŒ Failed to index {method.get('name')}: {e}")

    async def reindex_all(self):
        """ĞŸĞµÑ€ĞµĞ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸)"""

        methods = await self.methods_db.get_all_methods()

        print(f"Reindexing {len(methods)} methods...")

        # Clear index
        self.query_engine.index = faiss.IndexFlatL2(384)

        # Reindex
        await self.bulk_index(methods)

        print("âœ… Reindexing complete")

    def find_similar_methods(self, method_id: str, top_k: int = 5):
        """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹"""

        method = self.methods_db.get_method(method_id)

        if not method.get('embedding'):
            raise ValueError("Method not indexed")

        embedding = np.array(method['embedding']['vector'])

        # Search
        distances, indices = self.query_engine.index.search(
            embedding.reshape(1, -1),
            top_k + 1  # +1 because method itself will be in results
        )

        # Filter out the method itself
        similar = []
        for distance, idx in zip(distances[0], indices[0]):
            similar_method = self.methods_db.get_method_by_index(idx)

            if similar_method['id'] != method_id:
                similar.append({
                    'method': similar_method,
                    'similarity': 1 / (1 + distance)
                })

        return similar[:top_k]

    async def suggest_relations(self, method_id: str):
        """ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ relations Ğ´Ğ»Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°"""

        # Find similar methods
        similar = self.find_similar_methods(method_id, top_k=10)

        suggestions = {
            'complements': [],
            'alternatives': []
        }

        for s in similar:
            similarity = s['similarity']

            if similarity > 0.85:
                # Very similar - probably alternative
                suggestions['alternatives'].append({
                    'method_id': s['method']['id'],
                    'reason': 'High similarity in capabilities',
                    'score': similarity
                })
            elif 0.6 < similarity <= 0.85:
                # Somewhat similar - might complement
                suggestions['complements'].append({
                    'method_id': s['method']['id'],
                    'reason': 'Related but different focus',
                    'score': similarity
                })

        return suggestions
```

---

## ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Pseudo-RAG Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°

âœ… **ĞĞµ Ğ¸Ğ·Ğ¾Ğ±Ñ€ĞµÑ‚Ğ°ĞµĞ¼ Ğ²ĞµĞ»Ğ¾ÑĞ¸Ğ¿ĞµĞ´**
- AI ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
- ĞŸĞµÑ€ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ proven solutions
- Faster problem solving

âœ… **ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²**
- ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
- Flexible pipelines
- Modular approach

âœ… **ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ**
- Ğ‘Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ½Ğ¾ Ñ€Ğ°ÑÑ‚ĞµÑ‚
- Self-improving (Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹)
- AI ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹

âœ… **Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ**
- ĞĞµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ñ Ğ½ÑƒĞ»Ñ
- Reuse tested methods
- Fewer errors

âœ… **ĞŸÑ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ**
- Ğ’Ğ¸Ğ´Ğ½Ğ¾ ĞºĞ°ĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ÑÑŒ
- Reproducible results
- Easier debugging

âœ… **Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ**
- ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ - ÑÑ‚Ğ¾ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
- AI - ÑÑ‚Ğ¾ universal problem solver
- Best of both worlds

---

## Use Cases

### Use Case 1: Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ°Ñ data processing Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°

```python
task = """
Process a large CSV file (10GB):
1. Clean invalid rows
2. Normalize dates
3. Extract entities from text columns
4. Join with external data
5. Calculate aggregations
6. Export to multiple formats (CSV, JSON, Parquet)
7. Generate summary report
"""

# AI queries Method DB
methods = method_db.search(task)

# Found methods:
# 1. csv-stream-processor (for large files)
# 2. data-cleaner
# 3. date-normalizer
# 4. entity-extractor
# 5. data-joiner
# 6. aggregation-calculator
# 7. multi-format-exporter
# 8. report-generator

# AI composes pipeline
pipeline = [
    'csv-stream-processor',    # Handle large file
    'data-cleaner',            # Clean
    'date-normalizer',         # Normalize
    'entity-extractor',        # Extract
    'data-joiner',             # Join
    'aggregation-calculator',  # Aggregate
    'multi-format-exporter',   # Export
    'report-generator'         # Report
]

# Execute
result = await execute_pipeline(pipeline, input_file='data.csv')
```

### Use Case 2: Creative content creation

```python
task = """
Create a marketing campaign:
1. Research target audience
2. Generate campaign ideas
3. Write copy for social media
4. Design visuals
5. Schedule posts
"""

# Methods found:
# 1. audience-research-assistant
# 2. campaign-idea-generator
# 3. social-copy-writer
# 4. image-generator
# 5. post-scheduler

# AI composes and executes
```

### Use Case 3: Software development task

```python
task = """
Add a new feature to codebase:
1. Understand existing code
2. Design the feature
3. Write code
4. Write tests
5. Generate documentation
6. Create PR
"""

# Methods:
# 1. codebase-analyzer
# 2. feature-designer
# 3. code-generator
# 4. test-generator
# 5. doc-generator
# 6. pr-creator
```

---

(ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¼ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼...)


# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²

## Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ

| ĞÑĞ¿ĞµĞºÑ‚ | Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: External Service | Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Method DB (Pseudo-RAG) |
|--------|----------------------------|----------------------------------|
| **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°** | Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ | Ğ‘Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² + Vector search |
| **Ğ”Ğ¾ÑÑ‚ÑƒĞ¿** | API endpoints | Semantic search |
| **Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚** | YAML/JSON skills | Method schemas Ñ embeddings |
| **Execution** | Service Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ | AI ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ |
| **Platform** | ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ñ‹Ğ¹ Ğ¾Ñ‚ LLM | Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ñ AI |
| **ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ** | Horizontal scaling | Vector DB scaling |
| **ĞŸĞ¾Ğ¸ÑĞº** | By ID/category/tags | Semantic similarity |
| **ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ** | Manual chaining | AI-driven composition |
| **ĞœĞ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ** | API subscriptions | Skill marketplace |
| **ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ** | ĞĞµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ | AI ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ |
| **ĞŸÑ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ** | API logs | Method pipeline visible |

## Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ°

### Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: External Service

**Ğ›ÑƒÑ‡ÑˆĞµ ĞºĞ¾Ğ³Ğ´Ğ°:**
- âœ… ĞÑƒĞ¶Ğ½Ğ° Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ LLM
- âœ… Ğ’Ğ°Ğ¶Ğ½Ğ° Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ monetization
- âœ… Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ strict security/compliance
- âœ… ĞĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ execution
- âœ… Enterprise ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ (SLA, support)

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ use cases:**
- Enterprise platform Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
- API Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… LLM providers
- Regulated industries (Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹, Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğ°)
- Mission-critical applications

### Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Method DB (Pseudo-RAG)

**Ğ›ÑƒÑ‡ÑˆĞµ ĞºĞ¾Ğ³Ğ´Ğ°:**
- âœ… AI Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
- âœ… ĞÑƒĞ¶Ğ½Ğ° flexibility Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
- âœ… Ğ’Ğ°Ğ¶Ğ½Ğ° Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
- âœ… Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ transparency (Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°)
- âœ… Continuous learning Ğ¾Ñ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ use cases:**
- AI agents Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾ÑÑ‚ÑŒÑ
- Creative problem solving
- Research & experimentation
- Personalized AI assistants

---

# Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´

## ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ

**ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ğ»ÑƒÑ‡ÑˆĞµĞµ Ğ¸Ğ· Ğ¾Ğ±Ğ¾Ğ¸Ñ… Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI Agent                        â”‚
â”‚  â€¢ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ                           â”‚
â”‚  â€¢ Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚
        â†“                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Method DB      â”‚    â”‚ External Service â”‚
â”‚  (Pseudo-RAG)    â”‚    â”‚   (API-based)    â”‚
â”‚                  â”‚    â”‚                  â”‚
â”‚ â€¢ Semantic       â”‚    â”‚ â€¢ Execution      â”‚
â”‚   search         â”‚    â”‚ â€¢ Monitoring     â”‚
â”‚ â€¢ Composition    â”‚    â”‚ â€¢ Billing        â”‚
â”‚ â€¢ Planning       â”‚    â”‚ â€¢ Security       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

```python
# hybrid_system.py - Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°

class HybridSkillsSystem:
    """Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° - Method DB + External Service"""

    def __init__(self):
        # Method DB Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
        self.method_db = MethodQueryEngine()

        # External Service Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
        self.skills_service = SkillsServiceClient(
            api_url='https://api.skills.com',
            api_key=os.getenv('SKILLS_API_KEY')
        )

    async def solve_task(self, task: str):
        """
        Workflow:
        1. Method DB: Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
        2. Method DB: ÑĞ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ
        3. External Service: Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ skills
        4. Return Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        """

        # 1. Search methods Ğ² Method DB
        methods = self.method_db.search_methods(task, top_k=10)

        print(f"Found {len(methods)} methods via semantic search")

        # 2. Plan composition
        composition = self.method_db.suggest_method_composition(
            task,
            methods
        )

        print("Planned pipeline:")
        for step in composition['pipeline']:
            print(f"  {step['step']}. {step['method_id']}")

        # 3. Execute Ñ‡ĞµÑ€ĞµĞ· External Service
        results = []

        for step in composition['pipeline']:
            method_id = step['method_id']

            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ input Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ³Ğ°
            step_input = results[-1]['result'] if results else task

            # Execute Ñ‡ĞµÑ€ĞµĞ· API
            result = await self.skills_service.execute_skill(
                skill_id=method_id,
                input_data={'input': step_input}
            )

            results.append({
                'step': step['step'],
                'method': method_id,
                'result': result['result']
            })

            print(f"âœ“ Step {step['step']} completed")

        return {
            'final_result': results[-1]['result'],
            'steps': results
        }

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
hybrid = HybridSkillsSystem()

task = "Analyze customer feedback from CSV and create report"

# Method DB Ğ½Ğ°Ğ¹Ğ´ĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹
# External Service Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚
result = await hybrid.solve_task(task)
```

## ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ°

âœ… **Best of both worlds:**
- Method DB Ğ´Ğ»Ñ intelligent planning
- External Service Ğ´Ğ»Ñ robust execution

âœ… **Flexibility:**
- AI Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ»ÑĞ±Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸
- Service Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ

âœ… **Scalability:**
- Method DB: vector search scales well
- External Service: horizontal scaling

âœ… **Security:**
- Sandboxed execution Ğ² service
- Rate limiting Ğ¸ access control

âœ… **Monetization:**
- Method DB: Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
- External Service: pay-per-execution

âœ… **Learning:**
- Method DB ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ÑÑ Ğ¾Ñ‚ feedback
- Service ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ usage analytics

---

# Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ°

## 1. Method DB Ñ ÑÑÑ‹Ğ»ĞºĞ°Ğ¼Ğ¸ Ğ½Ğ° External Service

```yaml
# method_hybrid.yaml

apiVersion: methods.ai/v1
kind: Method
metadata:
  id: file-organizer-by-type
  name: File Organizer by Type

# Semantic info Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
semantics:
  purpose: Organize files by type
  capabilities: [...]
  suitable_for: [...]

# Ğ¡ÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° implementation Ğ² External Service
implementation:
  type: external-service
  service_url: https://api.skills.com
  skill_id: file-organizer-by-type
  version: 2.1.0

# Authentication
execution:
  requires_auth: true
  rate_limit: 100/hour
  cost: 0.01  # USD per execution

# ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ (ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ¸Ğ· service)
metrics:
  usage_count: 1543  # from service
  success_rate: 0.94  # from service
  avg_duration_ms: 2341  # from service
```

## 2. External Service Ñ Method DB Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹

```python
# skills_service_with_method_db.py

class SkillsServiceWithMethodDB:
    """External Service Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ Method DB"""

    def __init__(self):
        self.executor = SkillsExecutor()
        self.method_indexer = MethodIndexer()

    async def register_skill(self, skill: Dict):
        """
        Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ skill:
        1. Ğ’ External Service (Ğ´Ğ»Ñ execution)
        2. Ğ’ Method DB (Ğ´Ğ»Ñ search)
        """

        # 1. Register Ğ² service
        service_id = await self.skills_registry.register(skill)

        # 2. Create method entry Ğ´Ğ»Ñ Method DB
        method = {
            'id': service_id,
            'name': skill['name'],
            'semantics': self.extract_semantics(skill),
            'implementation': {
                'type': 'external-service',
                'service_url': self.base_url,
                'skill_id': service_id
            },
            'metrics': {
                'usage_count': 0,
                'success_rate': 1.0,
                'avg_duration_ms': 0
            }
        }

        # 3. Index Ğ² Method DB
        await self.method_indexer.index_method(method)

        return service_id

    async def execute_skill_and_update_method_db(
        self,
        skill_id: str,
        input_data: Dict
    ):
        """Execute skill Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ² Method DB"""

        # Execute
        result = await self.executor.execute(skill_id, input_data)

        # Update metrics Ğ² Method DB
        await self.method_indexer.update_metrics(
            method_id=skill_id,
            metrics={
                'usage_count': '+1',
                'success_rate': result['success'],
                'duration_ms': result['duration_ms']
            }
        )

        return result

    def extract_semantics(self, skill: Dict) -> Dict:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ semantic info Ğ¸Ğ· skill"""

        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ LLM Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ semantics
        prompt = f"""
        From this skill definition, extract semantic information:

        Name: {skill['name']}
        Description: {skill['description']}
        Instructions: {skill['instructions'][:500]}
        Examples: {skill.get('examples', [])[:2]}

        Generate:
        1. Purpose (concise description)
        2. Capabilities (list)
        3. Suitable for (use cases)
        4. Prerequisites
        5. Expected outcomes

        Return JSON.
        """

        semantics = llm.generate(prompt)

        return semantics
```

## 3. AI Agent Ñ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ¾Ğ¼

```python
# hybrid_ai_agent.py

class HybridAIAgent:
    """AI Agent Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Method DB + External Service"""

    def __init__(self):
        self.method_db = MethodQueryEngine()
        self.skills_service = SkillsServiceClient()
        self.cache = MethodCache()  # Local cache

    async def solve_task(
        self,
        task: str,
        execution_mode: str = 'auto'
    ):
        """
        Execution modes:
        - 'auto': AI Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ best approach
        - 'local': Execute Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ ĞµÑĞ»Ğ¸ possible
        - 'service': Always use external service
        - 'hybrid': Plan locally, execute remotely
        """

        # 1. Find methods
        methods = await self.method_db.search_methods(task)

        # 2. Choose execution strategy
        if execution_mode == 'auto':
            strategy = self.choose_execution_strategy(methods, task)
        else:
            strategy = execution_mode

        # 3. Execute based on strategy
        if strategy == 'local':
            # Execute locally if methods are simple
            result = await self.execute_locally(methods, task)

        elif strategy == 'service':
            # Use external service
            result = await self.execute_via_service(methods, task)

        elif strategy == 'hybrid':
            # Plan locally, execute parts remotely
            result = await self.execute_hybrid(methods, task)

        return result

    def choose_execution_strategy(
        self,
        methods: List[Dict],
        task: str
    ) -> str:
        """AI Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ"""

        # Ğ¤Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹:
        # - Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
        # - Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğº Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼
        # - Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ API calls
        # - Latency requirements
        # - Security/privacy

        complexity_score = self.calculate_complexity(methods)
        cost = self.estimate_cost(methods)
        latency_requirement = self.analyze_latency_needs(task)

        if complexity_score < 0.3 and cost < 0.10:
            return 'local'  # Simple and cheap - do locally

        elif complexity_score > 0.7 or cost > 1.00:
            return 'service'  # Complex or expensive - use service

        else:
            return 'hybrid'  # Mix of local and remote

    async def execute_hybrid(
        self,
        methods: List[Dict],
        task: str
    ):
        """Hybrid execution - some local, some remote"""

        composition = self.method_db.suggest_method_composition(
            task,
            methods
        )

        results = []

        for step in composition['pipeline']:
            method = next(
                m for m in methods
                if m['method']['id'] == step['method_id']
            )

            # Decide: local or remote?
            if self.can_execute_locally(method):
                # Execute locally
                result = await self.execute_method_locally(
                    method,
                    input_data=results[-1] if results else task
                )
            else:
                # Execute via service
                result = await self.skills_service.execute_skill(
                    skill_id=method['method']['id'],
                    input_data=results[-1] if results else task
                )

            results.append(result)

        return {
            'final_result': results[-1],
            'steps': results
        }

    def can_execute_locally(self, method: Dict) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾"""

        # Check ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ local implementation
        impl = method['method'].get('implementation', {})

        if impl['type'] == 'claude-skill':
            # Claude skills Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾
            return True

        elif impl['type'] == 'python' and self.has_dependencies(method):
            # Python scripts ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ dependencies
            return True

        elif impl['type'] == 'external-service':
            # ĞÑƒĞ¶ĞµĞ½ external service
            return False

        return False
```

## 4. ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

```python
# method_cache.py

class MethodCache:
    """Cache Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² execution"""

    def __init__(self):
        self.cache = {}  # In-memory
        self.redis = redis.Redis()  # Persistent

    async def get(
        self,
        method_id: str,
        input_hash: str
    ) -> Optional[Dict]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ· cache"""

        cache_key = f"{method_id}:{input_hash}"

        # Try in-memory first
        if cache_key in self.cache:
            return self.cache[cache_key]

        # Try Redis
        cached = self.redis.get(cache_key)
        if cached:
            result = json.loads(cached)
            # Populate in-memory cache
            self.cache[cache_key] = result
            return result

        return None

    async def set(
        self,
        method_id: str,
        input_hash: str,
        result: Dict,
        ttl: int = 3600  # 1 hour
    ):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ² cache"""

        cache_key = f"{method_id}:{input_hash}"

        # In-memory
        self.cache[cache_key] = result

        # Redis with TTL
        self.redis.setex(
            cache_key,
            ttl,
            json.dumps(result)
        )

    def hash_input(self, input_data: Any) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ hash input Ğ´Ğ»Ñ caching"""
        import hashlib

        # Convert to canonical JSON
        canonical = json.dumps(input_data, sort_keys=True)

        # SHA256 hash
        hash_obj = hashlib.sha256(canonical.encode())

        return hash_obj.hexdigest()

# Usage in agent

class OptimizedHybridAgent(HybridAIAgent):
    """Agent Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼"""

    def __init__(self):
        super().__init__()
        self.cache = MethodCache()

    async def execute_method(
        self,
        method: Dict,
        input_data: Any
    ):
        """Execute Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼"""

        method_id = method['method']['id']
        input_hash = self.cache.hash_input(input_data)

        # Check cache
        cached = await self.cache.get(method_id, input_hash)

        if cached:
            print(f"âœ“ Cache hit for {method['method']['name']}")
            return cached

        # Execute
        if self.can_execute_locally(method):
            result = await self.execute_method_locally(method, input_data)
        else:
            result = await self.skills_service.execute_skill(
                skill_id=method_id,
                input_data=input_data
            )

        # Cache result
        await self.cache.set(method_id, input_hash, result)

        return result
```

---

# Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

## Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ñƒ

### Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1 (External Service) ĞµÑĞ»Ğ¸:
- ğŸ¯ ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: Platform-as-a-Service
- ğŸ¯ ĞÑƒĞ¶Ğ½Ğ° Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ LLM
- ğŸ¯ Enterprise ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹
- ğŸ¯ Monetization Ñ‡ĞµÑ€ĞµĞ· API
- ğŸ¯ Strict security/compliance

### Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2 (Method DB) ĞµÑĞ»Ğ¸:
- ğŸ¯ ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: AI-native solution
- ğŸ¯ ĞÑƒĞ¶Ğ½Ğ° flexibility ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸
- ğŸ¯ Research & experimentation
- ğŸ¯ Personalized AI assistants
- ğŸ¯ Continuous learning

### Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ ĞµÑĞ»Ğ¸:
- ğŸ¯ ĞÑƒĞ¶Ğ½Ñ‹ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¾Ğ±Ğ¾Ğ¸Ñ…
- ğŸ¯ Ğ Ğ°Ğ·Ğ½Ñ‹Ğµ use cases
- ğŸ¯ ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ + Flexibility
- ğŸ¯ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğº complexity Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸

## Roadmap Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ñ

### Phase 1: MVP (2-3 Ğ¼ĞµÑÑÑ†Ğ°)
1. **Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2 (Method DB)** - Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ´Ğ»Ñ MVP
   - Vector database setup
   - Basic method indexing
   - Semantic search
   - Simple AI integration

### Phase 2: Scale (3-6 Ğ¼ĞµÑÑÑ†ĞµĞ²)
2. **Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1 (External Service)**
   - API infrastructure
   - Skills executor
   - Monitoring & billing
   - Enterprise features

### Phase 3: Optimize (6-12 Ğ¼ĞµÑÑÑ†ĞµĞ²)
3. **Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´**
   - Integrate Method DB + Service
   - Intelligent routing
   - Caching layer
   - Advanced features

## ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ ÑƒÑĞ¿ĞµÑ…Ğ°

**Method DB:**
- Search relevance > 85%
- Method composition quality > 80%
- User satisfaction > 4.5/5

**External Service:**
- Uptime > 99.9%
- API latency < 200ms (p95)
- Success rate > 98%

**Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹:**
- Cache hit rate > 60%
- Cost reduction > 40%
- Performance improvement > 30%

---

# ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€

## ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ workflow Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

```python
# complete_example.py - ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€

import asyncio

async def main():
    # Initialize Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°
    system = HybridSkillsSystem(
        method_db_url='https://methods.ai',
        service_api_url='https://api.skills.com',
        api_key='your-api-key'
    )

    # ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ´Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
    task = """
    I have a dataset of 10,000 customer reviews.
    I need to:
    1. Clean and preprocess the text
    2. Perform sentiment analysis
    3. Extract key topics
    4. Identify trends over time
    5. Generate executive summary report
    6. Create visualizations
    """

    print("ğŸ¯ Task:", task)
    print()

    # 1. Method DB: Semantic search
    print("ğŸ” Searching Method DB for relevant methods...")
    methods = await system.method_db.search_methods(
        task_description=task,
        top_k=10
    )

    print(f"Found {len(methods)} relevant methods:")
    for m in methods[:5]:
        print(f"  âœ“ {m['method']['name']} (score: {m['final_score']:.2f})")
    print()

    # 2. Method DB: Plan composition
    print("ğŸ“ Planning pipeline...")
    composition = await system.method_db.suggest_method_composition(
        task=task,
        methods=methods
    )

    print("Planned pipeline:")
    for step in composition['pipeline']:
        print(f"  {step['step']}. {step['method_id']}")
    print()

    # 3. Hybrid execution
    print("âš™ï¸  Executing hybrid pipeline...")

    results = []

    for step in composition['pipeline']:
        method_id = step['method_id']
        method = next(m for m in methods if m['method']['id'] == method_id)

        print(f"Step {step['step']}: {method['method']['name']}...")

        # Get input
        step_input = results[-1]['result'] if results else task

        # Choose execution: local or remote
        if system.can_execute_locally(method):
            print("  â†’ Executing locally")
            result = await system.execute_locally(method, step_input)
        else:
            print("  â†’ Executing via External Service")
            result = await system.execute_via_service(method, step_input)

        results.append({
            'step': step['step'],
            'method': method_id,
            'result': result,
            'execution': 'local' if system.can_execute_locally(method) else 'remote'
        })

        print(f"  âœ“ Completed in {result['duration_ms']}ms")
        print()

    # 4. Return final result
    print("âœ… Task completed!")
    print()
    print("Summary:")
    print(f"  Total steps: {len(results)}")
    print(f"  Local executions: {sum(1 for r in results if r['execution'] == 'local')}")
    print(f"  Remote executions: {sum(1 for r in results if r['execution'] == 'remote')}")
    print(f"  Total duration: {sum(r['result']['duration_ms'] for r in results)}ms")
    print()
    print("Final result:")
    print(results[-1]['result']['output'][:500] + "...")

if __name__ == '__main__':
    asyncio.run(main())

# Output:
# ğŸ¯ Task: I have a dataset of 10,000 customer reviews...
#
# ğŸ” Searching Method DB for relevant methods...
# Found 10 relevant methods:
#   âœ“ Text Preprocessor (score: 0.92)
#   âœ“ Sentiment Analyzer (score: 0.89)
#   âœ“ Topic Extractor (score: 0.87)
#   âœ“ Trend Analyzer (score: 0.84)
#   âœ“ Report Generator (score: 0.81)
#
# ğŸ“ Planning pipeline...
# Planned pipeline:
#   1. text-preprocessor
#   2. sentiment-analyzer
#   3. topic-extractor
#   4. trend-analyzer
#   5. report-generator
#   6. visualization-creator
#
# âš™ï¸  Executing hybrid pipeline...
# Step 1: Text Preprocessor...
#   â†’ Executing via External Service
#   âœ“ Completed in 2341ms
#
# Step 2: Sentiment Analyzer...
#   â†’ Executing via External Service
#   âœ“ Completed in 5678ms
#
# Step 3: Topic Extractor...
#   â†’ Executing locally
#   âœ“ Completed in 1234ms
#
# [...]
#
# âœ… Task completed!
#
# Summary:
#   Total steps: 6
#   Local executions: 2
#   Remote executions: 4
#   Total duration: 15432ms
```

---

**Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½:** 2026-01-28
**Ğ’ĞµÑ€ÑĞ¸Ñ:** 1.0 Complete
**ĞÑ…Ğ²Ğ°Ñ‚:** 2 Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ° + Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´
**Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ† ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ñ:** ~150

## ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹

1. **Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1 (External Service)** - Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ enterprise Ğ¸ monetization
2. **Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2 (Method DB / Pseudo-RAG)** - Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ AI-native workflows
3. **Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´** - best of both worlds, Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ production

ĞĞ±Ğ° Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ° Ğ¶Ğ¸Ğ·Ğ½ĞµÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹ Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ! ğŸš€

